{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f451cc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "\n",
    "Web scraping is the process of extracting data from websites. It involves parsing HTML content and retrieving specific \n",
    "information such as text, images, links, or structured data from web pages. Web scraping is used to automate the process of \n",
    "gathering data from the internet, saving time and effort compared to manual data collection.\n",
    "Three areas where web scraping is commonly used to get data:\n",
    "\n",
    "Business Intelligence: Companies use web scraping to gather market research data, competitor analysis, pricing information, and \n",
    "    customer reviews from various websites to make informed business decisions.\n",
    "Content Aggregation: News aggregators, job boards, and e-commerce websites use web scraping to collect and display relevant \n",
    "    content, job listings, product information, and prices from multiple sources in one place.\n",
    "Research and Analysis: Researchers, journalists, and analysts use web scraping to collect data for academic research, \n",
    "    investigative journalism, sentiment analysis, and trend analysis from online sources such as social media platforms, \n",
    "    forums, and blogs.\n",
    "Q2. What are the different methods used for Web Scraping?\n",
    "\n",
    "Different methods used for web scraping include:\n",
    "\n",
    "Manual Scraping: Manually extracting data from web pages using copy-pasting or browser developer tools.\n",
    "Regular Expressions (Regex): Using regular expressions to search and extract specific patterns of text from HTML content.\n",
    "DOM Parsing: Parsing HTML documents using libraries like BeautifulSoup or lxml to extract data based on the document's structure\n",
    "    and elements.\n",
    "XPath: Using XPath expressions to navigate and select elements within an HTML document for extraction.\n",
    "APIs: Utilizing APIs provided by websites to access structured data directly, if available.\n",
    "Q3. What is Beautiful Soup? Why is it used?\n",
    "\n",
    "Beautiful Soup is a Python library used for web scraping HTML and XML documents. It provides tools for parsing HTML and \n",
    "navigating the parse tree, allowing developers to extract specific data from web pages easily.\n",
    "\n",
    "Beautiful Soup is used because it simplifies the process of web scraping by providing a high-level interface for working with \n",
    "HTML documents. It handles common tasks like parsing, navigating the DOM (Document Object Model), searching for specific \n",
    "elements, and extracting data, making it easier and more efficient to scrape web pages.\n",
    "\n",
    "Q4. Why is Flask used in this Web Scraping project?\n",
    "\n",
    "Flask is used in web scraping projects to create web applications that serve scraped data to users. Flask provides a lightweight\n",
    "and flexible framework for building web servers and APIs, making it suitable for serving web scraping results to clients. In \n",
    "this project, Flask can be used to create a web interface where users can input URLs to scrape and view the scraped data.\n",
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service.\n",
    "\n",
    "AWS Lambda: AWS Lambda is a serverless computing service that allows running code without provisioning or managing servers. In \n",
    "    this project, AWS Lambda can be used to run web scraping scripts periodically or in response to events, ensuring that the \n",
    "    scraping process is automated and scalable.\n",
    "\n",
    "Amazon S3 (Simple Storage Service): Amazon S3 is an object storage service that allows storing and retrieving large amounts of \n",
    "    data. In this project, Amazon S3 can be used to store scraped data files, images, or other resources retrieved during the \n",
    "    scraping process.\n",
    "\n",
    "Amazon DynamoDB: Amazon DynamoDB is a fully managed NoSQL database service that provides fast and predictable performance with \n",
    "    seamless scalability. In this project, DynamoDB can be used to store structured data extracted from web pages during the \n",
    "    scraping process, allowing easy retrieval and querying of scraped data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
